{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrafficSign-Conv2DGAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kY5SlcPumq8N","colab_type":"code","colab":{}},"cell_type":"code","source":["#### GOOGLE DRIVE SPECIFIC ##########################\n","# Make sure that you have GPU selected in the Runtime\n","# If you do, will print Found GPU at: /device:GPU:0\n","# Else go to Runtime -> Change Runtime Type\n","\n","import tensorflow as tf\n","# device_name = tf.test.gpu_device_name()\n","# if device_name != '/device:GPU:0':\n","#   raise SystemError('GPU device not found')\n","# print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0T-TJQGSyfs3","colab_type":"code","outputId":"182451d6-c382-45a0-cb3a-d240a36ede59","executionInfo":{"status":"ok","timestamp":1554065480544,"user_tz":240,"elapsed":6198,"user":{"displayName":"Abdurrahman Cam","photoUrl":"https://lh3.googleusercontent.com/-k26CU-cLkKc/AAAAAAAAAAI/AAAAAAAAADA/qhdRTerZnrE/s64/photo.jpg","userId":"12952516305974938564"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# CODE SNIPPET TO ACCESS THE FILES IN GOOGLE DRIVE (GO TO BROWSER AND VERIFY)\n","# THEN YOU CAN ACCESS THE FILES ON LEFT SIDEBAR (copy path)\n","# (https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q#scrollTo=H4SJ-tGNkOeY)\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","# drive.mount('/content/drive')\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# After executing the cell above, Drive\n","# files will be present in \"/content/drive/My Drive\".\n","# !ls \"/content/drive/My Drive\"\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"tEgacIZfy5B7","colab_type":"code","colab":{}},"cell_type":"code","source":["# googlepath exists for googledrive finding the files. \n","googlepath = \"drive/My Drive/SeniorDesign19\"\n","foldernamepath = googlepath + \"/Data/32BY32\"\n","savedpath = googlepath + \"/TrafficSignGAN/savedImages/\"\n","modelpath = googlepath + \"/TrafficSignGAN/savedModels/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2U-Nf10rbm-v","colab_type":"code","colab":{}},"cell_type":"code","source":["## Some Parameters to run code\n","\n","# Make this True when you want to output single images. Keep it at false\n","# when you want to train the model. Note in either case make sure that\n","# only the models you want to use for generating or continuing training on\n","# are the only ones in the folder savedModels.\n","\n","# Approach: First keep this false, train model, then make true and output\n","# single images.\n","runOnlyOneModel = True\n","                       \n","\n","# *Note: Be sure to remove the savedModels when training\n","# a new class else it will start training using that.\n","classToTrain = 11\n","\n","### For reference in our dataset: Largest 10 Classes ###\n","##Done\n","# # Class 28\n","# # Class 54\n","# # Class 3\n","# # Class 5\n","# # Class 55\n","# # Class 35\n","# # Class 7\n","# # Class 30\n","# # Class 16\n","# # Class 11\n","\n","## To Do\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jAcBAE9H5q5h","colab_type":"code","outputId":"bf6c0802-ca56-4810-9cae-86b6658e6f79","executionInfo":{"status":"ok","timestamp":1554065480568,"user_tz":240,"elapsed":6042,"user":{"displayName":"Abdurrahman Cam","photoUrl":"https://lh3.googleusercontent.com/-k26CU-cLkKc/AAAAAAAAAAI/AAAAAAAAADA/qhdRTerZnrE/s64/photo.jpg","userId":"12952516305974938564"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from __future__ import print_function, division\n","\n","from keras.layers import Input, Dense, Flatten, Dropout, Reshape\n","from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Model, load_model\n","from keras.optimizers import Adam\n","\n","from keras.datasets import cifar10\n","import keras.backend as K\n","\n","from keras.models import model_from_json\n","\n","\n","import matplotlib.pyplot as plt\n","\n","import sys\n","import numpy as np\n","import cv2\n","import os\n","import re\n","\n","import numpy as np\n","\n","import random\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"IBL0xYV56btS","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_generator(input_layer):\n","  '''\n","  Requires the input layer as input, outputs the model and the final layer\n","  '''\n","  \n","  hid = Dense(128 * 16 * 16, activation='relu')(input_layer)    \n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","  hid = Reshape((16, 16, 128))(hid)\n","\n","  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)    \n","  #hid = Dropout(0.5)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  #hid = Dropout(0.5)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","                      \n","  hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n","  out = Activation(\"tanh\")(hid)\n","\n","  model = Model(input_layer, out)\n","  model.summary()\n","  \n","  return model, out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KTTBDCMYKos8","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_discriminator(input_layer):\n","  '''\n","  Requires the input layer as input, outputs the model and the final layer\n","  '''\n","\n","  hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n","  hid = BatchNormalization(momentum=0.9)(hid)\n","  hid = LeakyReLU(alpha=0.1)(hid)\n","\n","  hid = Flatten()(hid)\n","  hid = Dropout(0.4)(hid)\n","  out = Dense(1, activation='sigmoid')(hid)\n","\n","  model = Model(input_layer, out)\n","\n","  model.summary()\n","\n","  return model, out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rEaPkXRgKsE_","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing import image\n","\n","def generate_noise(n_samples, noise_dim):\n","  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n","  return X\n","\n","def show_imgs(batchidx):\n","  noise = generate_noise(9, 100)\n","  gen_imgs = generator.predict(noise)\n","  \n","  if runOnlyOneModel:\n","    # want to just output single images\n","    fig, axs = plt.subplots(1, 1)\n","    count = 0\n","    for i in range(9):\n","      # Dont scale the images back, let keras handle it\n","      img = image.array_to_img(gen_imgs[count], scale=True)\n","      axs.imshow(img)\n","      axs.axis('off')\n","      count += 1\n","      fig.savefig(savedpath + \"class_{}_singleImages/\".format(classToTrain) + \"{}.png\".format(batchidx + \"_generated_{}\".format(str(count))))\n","      plt.close()\n","  else:\n","    fig, axs = plt.subplots(3, 3)\n","    count = 0\n","    for i in range(3):\n","      for j in range(3):\n","        # Dont scale the images back, let keras handle it\n","        img = image.array_to_img(gen_imgs[count], scale=True)\n","        axs[i,j].imshow(img)\n","        axs[i,j].axis('off')\n","        count += 1\n","    #   plt.show()\n","    fig.savefig(savedpath + \"class_{}_trainingProgression/\".format(classToTrain) + \"{}.png\".format(batchidx))\n","    plt.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UbyGmQoxKujm","colab_type":"code","outputId":"23aebc16-6536-4425-ad56-084f786370f0","executionInfo":{"status":"ok","timestamp":1554065485441,"user_tz":240,"elapsed":10780,"user":{"displayName":"Abdurrahman Cam","photoUrl":"https://lh3.googleusercontent.com/-k26CU-cLkKc/AAAAAAAAAAI/AAAAAAAAADA/qhdRTerZnrE/s64/photo.jpg","userId":"12952516305974938564"}},"colab":{"base_uri":"https://localhost:8080/","height":1850}},"cell_type":"code","source":["# GAN creation\n","starting_epoch = 0\n","\n","model_names = os.listdir(modelpath)\n","model_names.sort(key = lambda x : (int(x.split('_')[2]), x.split('_')[3][:4]))\n","# print(model_names)\n","\n","if len(model_names) != 0:\n","    # disc, gan, gen \n","    one = model_names[-3]\n","    m = re.findall(r'[a-z]+', one)\n","    assert m[1] == \"disc\", print(\"wanted: disc, got: \", m[1])\n","    \n","    two = model_names[-2]\n","    m = re.findall(r'[a-z]+', two)\n","    assert m[1] == \"gan\", print(\"wanted: gan, got: \",m[1])\n","    \n","    three = model_names[-1]\n","    m = re.findall(r'[a-z]+', three)\n","    assert m[1] == \"gen\", print(\"wanted: gen, got: \", m[1])\n","    \n","    img_input = Input(shape=(32,32,3))\n","    discriminator, disc_out = get_discriminator(img_input)\n","    discriminator.load_weights(modelpath + one)\n","    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    discriminator.trainable = False\n","\n","    noise_input = Input(shape=(100,))\n","    generator, gen_out = get_generator(noise_input)\n","    generator.load_weights(modelpath + three)\n","\n","    gan_input = Input(shape=(100,))    \n","    x = generator(gan_input)\n","    gan_out = discriminator(x)\n","    gan = Model(gan_input, gan_out)\n","    gan.summary()\n","\n","    gan.load_weights(modelpath + two)\n","    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n","    \n","    m = re.findall(r'[0-9]+', one)\n","    starting_epoch = int(m[1])\n","else:\n","    img_input = Input(shape=(32,32,3))\n","    discriminator, disc_out = get_discriminator(img_input)\n","    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    discriminator.trainable = False\n","\n","    noise_input = Input(shape=(100,))\n","    generator, gen_out = get_generator(noise_input)\n","\n","    gan_input = Input(shape=(100,))    \n","    x = generator(gan_input)\n","    gan_out = discriminator(x)\n","    gan = Model(gan_input, gan_out)\n","    gan.summary()\n","\n","    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 4, 4, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 2049      \n","=================================================================\n","Total params: 794,497\n","Trainable params: 793,473\n","Non-trainable params: 1,024\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32768)             3309568   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 32768)             131072    \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 32768)             0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 16, 16, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 32, 32, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 32, 32, 128)       409728    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 32, 32, 3)         9603      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 3)         0         \n","=================================================================\n","Total params: 4,943,747\n","Trainable params: 4,877,187\n","Non-trainable params: 66,560\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","model_2 (Model)              (None, 32, 32, 3)         4943747   \n","_________________________________________________________________\n","model_1 (Model)              (None, 1)                 794497    \n","=================================================================\n","Total params: 5,738,244\n","Trainable params: 4,877,187\n","Non-trainable params: 861,057\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"YltMiIuQKylv","colab_type":"code","outputId":"1bb5765b-9863-40af-8f4d-adacebe904b9","executionInfo":{"status":"ok","timestamp":1554065518606,"user_tz":240,"elapsed":43908,"user":{"displayName":"Abdurrahman Cam","photoUrl":"https://lh3.googleusercontent.com/-k26CU-cLkKc/AAAAAAAAAAI/AAAAAAAAADA/qhdRTerZnrE/s64/photo.jpg","userId":"12952516305974938564"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["BATCH_SIZE = 50\n","\n","## MODIFIDED TO TAKE IMAGES FROM FOLDER########\n","img_names = os.listdir(foldernamepath)\n","\n","# # Get training images\n","\n","# ## Find the 10 classes with most data in our training set to train them \n","# ## separately\n","# freq = [0] * 100\n","\n","# for img in img_names:\n","#     m = re.findall(r'[0-9]+', img)\n","#     classNum = int(m[0])\n","#     freq[classNum] = freq[classNum] + 1\n","\n","# sortedFreq = [0] * 100\n","# for i in range(len(freq)):\n","#     sortedFreq[i] = (i, freq[i])\n","\n","# sortedFreq = sorted(sortedFreq, key = lambda x : x[1], reverse = True)\n","\n","# # print(sortedFreq[:10])\n","\n","# mostFreq = []\n","# for dataClass in sortedFreq[:10]:\n","#     mostFreq.append(dataClass[0])\n","\n","# # print(mostFreq)\n","\n","# ### Largest 10 Classes ###\n","# Class 28 with Frequency 446\n","# Class 54 with Frequency 324\n","# Class 3 with Frequency 260\n","# Class 5 with Frequency 194\n","\n","# Class 55 with Frequency 162\n","# Class 35 with Frequency 156\n","# Class 7 with Frequency 152\n","# Class 30 with Frequency 150\n","# Class 16 with Frequency 142\n","# Class 11 with Frequency 138\n","\n","classImg = []\n","\n","# training on one class at a time\n","for img in img_names:\n","    m = re.findall(r'[0-9]+', img)\n","    if int(m[0]) == classToTrain:\n","        classImg.append(img)\n","\n","img_names = classImg\n","print(\"Training on # of Images: \", len(img_names))\n","\n","# training on the img files in img_names\n","random.shuffle(img_names)\n","x = []\n","for img_name in img_names:\n","    if img_name is not None:\n","        im = np.asarray(cv2.imread(foldernamepath + \"/\" + img_name, cv2.IMREAD_COLOR))\n","        if im.shape[0] == 32 and im.shape[1] == 32:\n","            x.append(im)\n","\n","X_train = np.asarray(x)  \n","\n","print (\"Training shape: {}\".format(X_train.shape))\n","\n","# Normalize data\n","X_train = (X_train - 127.5) / 127.5\n"," \n","num_batches = int(X_train.shape[0]/BATCH_SIZE)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Training on # of Images:  138\n","Training shape: (138, 32, 32, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"jF6mvjQUK0ZT","colab_type":"code","colab":{}},"cell_type":"code","source":["if runOnlyOneModel:\n","    for i in range(50):\n","        show_imgs(\"class_\" + str(classToTrain) + \"_singleImage_\" + str(i) + \"_fromModel_\" + str(starting_epoch))\n","else:\n","    N_EPOCHS = 3000\n","    for epoch in range(N_EPOCHS):\n","\n","      cum_d_loss = 0.\n","      cum_g_loss = 0.\n","\n","      for batch_idx in range(num_batches):\n","        # Get the next set of real images to be used in this iteration\n","        images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n","\n","        noise_data = generate_noise(BATCH_SIZE, 100)\n","        generated_images = generator.predict(noise_data)\n","\n","        # Train on soft labels (add noise to labels as well)\n","        noise_prop = 0.05 # Randomly flip 5% of labels\n","\n","        # Prepare labels for real data\n","        true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n","        flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n","        true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n","\n","        # Train discriminator on real data\n","        d_loss_true = discriminator.train_on_batch(images, true_labels)\n","\n","        # Prepare labels for generated data\n","        gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n","        flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n","        gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n","\n","        # Train discriminator on generated data\n","        d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n","\n","        d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n","        cum_d_loss += d_loss\n","\n","        # Train generator\n","        noise_data = generate_noise(BATCH_SIZE, 100)\n","        g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n","        cum_g_loss += g_loss\n","\n","      print('  Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1+starting_epoch, cum_g_loss/num_batches, cum_d_loss/num_batches))\n","\n","      if epoch % 50 == 0 or epoch <= 50:\n","          show_imgs(\"epoch\" + str(epoch + starting_epoch))\n","\n","      if epoch % 500 == 0 and epoch != 0:\n","        generator.save_weights(modelpath + \"class_\" + str(classToTrain) + \"_{}_gen.h5\".format(epoch + starting_epoch))\n","        discriminator.save_weights(modelpath +  \"class_\" + str(classToTrain) + \"_{}_disc.h5\".format(epoch + starting_epoch))\n","        gan.save_weights(modelpath +  \"class_\" + str(classToTrain) + \"_{}_gan.hdf5\".format(epoch + starting_epoch))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G--tLjfKwzPB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"yLcW00AWLSlv","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}