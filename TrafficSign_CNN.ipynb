{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrafficSign-CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kY5SlcPumq8N",
        "colab_type": "code",
        "outputId": "ceb71656-f62a-4839-8ec6-8314f34f9eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#### GOOGLE DRIVE SPECIFIC ##########################\n",
        "# Make sure that you have GPU selected in the Runtime\n",
        "# If you do, will print Found GPU at: /device:GPU:0\n",
        "# Else go to Runtime -> Change Runtime Type\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0T-TJQGSyfs3",
        "colab_type": "code",
        "outputId": "d9f6e9ba-9379-4650-edf9-d249ef0e1008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# CODE SNIPPET TO ACCESS THE FILES IN GOOGLE DRIVE (GO TO BROWSER AND VERIFY)\n",
        "# THEN YOU CAN ACCESS THE FILES ON LEFT SIDEBAR (copy path)\n",
        "# (https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q#scrollTo=H4SJ-tGNkOeY)\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "# drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "# !ls \"/content/drive/My Drive\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tEgacIZfy5B7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# googlepath exists for googledrive finding the files. \n",
        "googlepath = \"drive/My Drive/SeniorDesign19\"\n",
        "\n",
        "# folder that holds the real data \n",
        "foldernamepath = googlepath + \"/Data/32BY32\"\n",
        "\n",
        "testdatapath = googlepath + \"/Data/32BY32TestSet\"\n",
        "\n",
        "# saved model path\n",
        "modelpath = googlepath + \"/TrafficSignGAN/cnnModel/\"\n",
        "\n",
        "# path to generated SINGLE images from GAN\n",
        "generatedpath = googlepath + \"/TrafficSignGAN/trainedModelsandOutputs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmHM1mNAWxre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Control whether to include generated images into CNN training\n",
        "includeGenerated = True\n",
        "\n",
        "# Which model to use. \n",
        "# Model 1 is from Keras CIFAR-10 CNN \n",
        "# Model 2 is Basic Lecun Network\n",
        "# Model 3 is Keras ConvNet\n",
        "modelNumber = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAcBAE9H5q5h",
        "colab_type": "code",
        "outputId": "04a93e6b-73b9-4714-f39c-21464ce662fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "\n",
        "from keras import optimizers, regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout, Activation\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.layers import Input, Reshape\n",
        "from keras.layers import BatchNormalization, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBL0xYV56btS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing on Different Models\n",
        "def build_model():\n",
        "  ######################\n",
        "    \n",
        "    if modelNumber == 1:       \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                          input_shape=(32,32,3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(32, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(64, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(10))\n",
        "        model.add(Activation('softmax'))\n",
        "    \n",
        "        # initiate RMSprop optimizer\n",
        "        opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "        # Let's train the model using RMSprop\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=opt,\n",
        "                      metrics=['accuracy'])\n",
        "        \n",
        "    elif modelNumber == 2:\n",
        "      \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(6, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal', input_shape=(32,32,3)))\n",
        "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "        model.add(Conv2D(16, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal'))\n",
        "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
        "        model.add(Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
        "        model.add(Dense(10, activation = 'softmax', kernel_initializer='he_normal'))\n",
        "        sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "    elif modelNumber == 3:\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "                      metrics=['accuracy'])\n",
        "        \n",
        "    else:\n",
        "        raise Exception(\"Model Number is not valid!\")\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTTBDCMYKos8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# lower learning rate as we increase training epochs\n",
        "def scheduler(epoch):\n",
        "    if epoch < 100:\n",
        "        return 0.01\n",
        "    if epoch < 150:\n",
        "        return 0.005\n",
        "    return 0.001\n",
        "  \n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0003        \n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YltMiIuQKylv",
        "colab_type": "code",
        "outputId": "45dd95a6-4f77-4768-b03f-213f642d6793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "### Getting the Data and Preprocessing\n",
        "\n",
        "## MODIFIDED TO TAKE IMAGES FROM FOLDER########\n",
        "img_names = os.listdir(foldernamepath)\n",
        "\n",
        "## Get the real images of the 10 classes we are using\n",
        "# Could preprocess once and just remove the other images as well...\n",
        "# But let's keep those images there, for now.\n",
        "\n",
        "realClassesSet = set([28, 54, 3, 5, 55, 35, 7, 30, 16, 11])\n",
        "\n",
        "# Need to map classesSet from 0-9 \n",
        "classMap = {}\n",
        "for index, i in enumerate(realClassesSet):\n",
        "  classMap[i] = index\n",
        "  if index == 10:\n",
        "    print(\"failed\")\n",
        "\n",
        "\n",
        "selectedImages = []\n",
        "\n",
        "for img in img_names:\n",
        "  m = img.split('_')[0]\n",
        "#   m = re.findall(r'[0-9]+', img)\n",
        "  classNum = int(m)\n",
        "  if classNum in realClassesSet:\n",
        "    selectedImages.append(img)\n",
        "\n",
        "img_names = selectedImages\n",
        "\n",
        "# shuffle these names\n",
        "random.shuffle(img_names)\n",
        "\n",
        "\n",
        "# Need to also create the y_labels for each image\n",
        "y_train = []\n",
        "x = []\n",
        "checkUp = 0\n",
        "realLength = len(img_names)\n",
        "\n",
        "for img_name in img_names:\n",
        "  checkUp += 1\n",
        "  if checkUp % 500 == 0:\n",
        "    print(\"At Real Image: \", checkUp, \" of total images: \", realLength)\n",
        "  if img_name is not None:\n",
        "    im = np.asarray(cv2.imread(foldernamepath + \"/\" + img_name, cv2.IMREAD_COLOR))\n",
        "    if im.shape[0] == 32 and im.shape[1] == 32:\n",
        "      x.append(im)\n",
        "      classLabel = int(img_name.split('_')[0])\n",
        "      y_train.append(classMap[classLabel])\n",
        "      \n",
        "currLength = len(x)\n",
        "print(\"# of Real Images: \", currLength)\n",
        "\n",
        "\n",
        "if includeGenerated:\n",
        "    classDir = []\n",
        "    # also the generated images for each class          \n",
        "    for classNum in realClassesSet:\n",
        "      classDir.extend(os.listdir(generatedpath + \"class_{0}/class_{0}_singleImages\".format(classNum)))\n",
        "\n",
        "    random.shuffle(classDir)\n",
        "\n",
        "    generatedLength = len(classDir)\n",
        "\n",
        "    checkUp = 0\n",
        "    for img_name in classDir:\n",
        "      checkUp += 1\n",
        "      if checkUp % 500 == 0:\n",
        "        print(\"At Generated Image: \", checkUp, \" of total images: \", generatedLength)\n",
        "      if img_name is not None:\n",
        "        classLabel = int(img_name.split('_')[1])\n",
        "        im = np.asarray(cv2.imread(generatedpath + \"class_{0}/class_{0}_singleImages\".format(classLabel) \n",
        "                                   + \"/\" + img_name, cv2.IMREAD_COLOR))\n",
        "        if im.shape[0] == 32 and im.shape[1] == 32:\n",
        "          x.append(im)\n",
        "          y_train.append(classMap[classLabel])\n",
        "\n",
        "    print(\"# of Generated Images: \", len(x) - currLength)\n",
        "    print(\"Training on # of Real + Generated Images: \", len(x))\n",
        "\n",
        "\n",
        "# prepare the test set\n",
        "checkUp = 0\n",
        "test_names = os.listdir(testdatapath)\n",
        "testLength = len(test_names)\n",
        "X_test_original = []\n",
        "y_test_original = []\n",
        "\n",
        "for img_name in test_names:\n",
        "  checkUp += 1\n",
        "  if checkUp % 500 == 0:\n",
        "    print(\"At Test Image: \", checkUp, \" of total images: \", testLength)\n",
        "  if img_name is not None:\n",
        "    im = np.asarray(cv2.imread(testdatapath + \"/\" + img_name, cv2.IMREAD_COLOR))\n",
        "    if im.shape[0] == 32 and im.shape[1] == 32:\n",
        "      X_test_original.append(im)\n",
        "      classLabel = int(img_name.split('_')[0])\n",
        "      y_test_original.append(classMap[classLabel])\n",
        "\n",
        "    \n",
        "y_train_original = y_train\n",
        "X_train_original = np.asarray(x)  \n",
        "print (\"Training shape: {}\".format(X_train_original.shape))\n",
        "\n",
        "X_test_original = np.asarray(X_test_original)   \n",
        "print (\"Testing shape: {}\".format(X_test_original.shape))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At Real Image:  500  of total images:  2124\n",
            "At Real Image:  1000  of total images:  2124\n",
            "At Real Image:  1500  of total images:  2124\n",
            "At Real Image:  2000  of total images:  2124\n",
            "# of Real Images:  2124\n",
            "At Generated Image:  500  of total images:  4500\n",
            "At Generated Image:  1000  of total images:  4500\n",
            "At Generated Image:  1500  of total images:  4500\n",
            "At Generated Image:  2000  of total images:  4500\n",
            "At Generated Image:  2500  of total images:  4500\n",
            "At Generated Image:  3000  of total images:  4500\n",
            "At Generated Image:  3500  of total images:  4500\n",
            "At Generated Image:  4000  of total images:  4500\n",
            "At Generated Image:  4500  of total images:  4500\n",
            "# of Generated Images:  4500\n",
            "Training on # of Real + Generated Images:  6624\n",
            "At Test Image:  500  of total images:  772\n",
            "Training shape: (6624, 32, 32, 3)\n",
            "Testing shape: (772, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iPOLDLdiIdPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training the CNN Model on the Images\n",
        "\n",
        "# Make first 500 of REAL and SHUFFLED images my \n",
        "# validation data\n",
        "\n",
        "threshold = 500\n",
        "\n",
        "# Doing this so I can rerun this code on the fly and not have it mess up\n",
        "y_val = y_train_original[:threshold]\n",
        "y_train = y_train_original[threshold:]\n",
        "y_test = y_test_original[0:]\n",
        "\n",
        "X_val = X_train_original[:threshold]\n",
        "X_train = X_train_original[threshold:]\n",
        "X_test = X_test_original[0:]\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_val = keras.utils.to_categorical(y_val, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Not sure this is best way to normalize.\n",
        "X_train /= 255.0\n",
        "X_val /= 255.0\n",
        "X_test /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G--tLjfKwzPB",
        "colab_type": "code",
        "outputId": "934c6f6d-d1f1-41a3-c1e9-e12989b9e451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1938
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "accuracies = []\n",
        "\n",
        "# Get the average accuracy over 10 runs\n",
        "for i in range(10):\n",
        "# build network\n",
        "    model = build_model()\n",
        "#     print(model.summary())\n",
        "    \n",
        "    if modelNumber == 2:\n",
        "        # set callback\n",
        "        tb_cb = TensorBoard(log_dir='./lenet', histogram_freq=0)\n",
        "        change_lr = LearningRateScheduler(scheduler)\n",
        "        cbks = [change_lr,tb_cb]\n",
        "\n",
        "        # start train\n",
        "        model.fit(X_train, y_train,\n",
        "                  batch_size=128,\n",
        "                  epochs=epochs,\n",
        "                  callbacks=cbks,\n",
        "                  validation_data=(X_val, y_val),\n",
        "                  shuffle=False,\n",
        "                  verbose=0)\n",
        "    elif modelNumber == 3:\n",
        "      \n",
        "        model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          shuffle=False,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)],\n",
        "          verbose=0)\n",
        "        \n",
        "    else:\n",
        "        model.fit(X_train, y_train,\n",
        "                  batch_size=128,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(X_val, y_val),\n",
        "                  shuffle=False,\n",
        "                  verbose=0)\n",
        "\n",
        "\n",
        "    # Score trained model.\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(\"Run {}\".format(i+1))\n",
        "    print(\"--------------------------------------------\")\n",
        "    print('Test loss:', scores[0])\n",
        "    print('Test accuracy:', scores[1])\n",
        "\n",
        "    print(\"Threshold: \", threshold)\n",
        "    print(\"Epochs: \", epochs)\n",
        "    print(\"Include Generated?: \", includeGenerated)\n",
        "    print(\"Model Number: \", modelNumber)\n",
        "    print(\"--------------------------------------------\")\n",
        "    print()\n",
        "    \n",
        "    accuracies.append(scores[1])\n",
        "    \n",
        "print(\"Model {}; Include Generated? {};\\navg acc of 10 runs: {};\\nstd dev: {}\".format(\n",
        "    modelNumber, includeGenerated, np.mean(accuracies), np.std(accuracies)))\n",
        "print()\n",
        "    \n",
        "# save model\n",
        "# model.save(modelpath + 'lenet.h5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Run 1\n",
            "--------------------------------------------\n",
            "Test loss: 1.353193498612261\n",
            "Test accuracy: 0.844559585492228\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 2\n",
            "--------------------------------------------\n",
            "Test loss: 1.3613188819992332\n",
            "Test accuracy: 0.8367875647668394\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 3\n",
            "--------------------------------------------\n",
            "Test loss: 1.5376259586178993\n",
            "Test accuracy: 0.8264248704663213\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 4\n",
            "--------------------------------------------\n",
            "Test loss: 1.4141085161706868\n",
            "Test accuracy: 0.844559585492228\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 5\n",
            "--------------------------------------------\n",
            "Test loss: 1.7147030807730002\n",
            "Test accuracy: 0.8082901554404145\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 6\n",
            "--------------------------------------------\n",
            "Test loss: 1.5190553220891019\n",
            "Test accuracy: 0.8367875647668394\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 7\n",
            "--------------------------------------------\n",
            "Test loss: 1.173895262188997\n",
            "Test accuracy: 0.844559585492228\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 8\n",
            "--------------------------------------------\n",
            "Test loss: 1.3681857215334003\n",
            "Test accuracy: 0.8393782383419689\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 9\n",
            "--------------------------------------------\n",
            "Test loss: 1.383834125926034\n",
            "Test accuracy: 0.8471502590673575\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Run 10\n",
            "--------------------------------------------\n",
            "Test loss: 1.4278745795959291\n",
            "Test accuracy: 0.8367875647668394\n",
            "Threshold:  500\n",
            "Epochs:  100\n",
            "Include Generated?:  True\n",
            "Model Number:  1\n",
            "--------------------------------------------\n",
            "\n",
            "Model 1; Include Generated? True;\n",
            "avg acc of 10 runs: 0.8365284974093266;\n",
            "std dev: 0.011018741097480175\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SmLd4R7aUanC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}